#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Multi-dimensional search benchmark: Compare search methods across multiple queries.

Dimensions:
1. Speed (time_ms)
2. Result Quality (relevance score distribution)
3. Ranking Stability (position changes vs baseline)
4. Coverage (unique files found)
"""
import subprocess
import sys
import os
import re
import json
import time
import io

# Fix Windows console encoding
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from pathlib import Path

os.chdir(r"D:\dongdiankaifa9\hydro_generator_module")

# Test queries covering different search intents
TEST_QUERIES = [
    ("çƒ­ç½‘ç»œè®¡ç®—", "Chinese: thermal network calculation"),
    ("ThermalResistance", "Code identifier"),
    ("boundary condition handling", "Natural language"),
    ("stator slot cooling", "Domain-specific"),
    ("def build", "Code pattern"),
]

# Search methods to compare
SEARCH_METHODS = [
    ("hybrid", None, "Hybrid (FTS+Vector RRF)"),
    ("vector", None, "Pure Vector"),
    ("cascade", "binary", "Cascade Binary"),
    ("cascade", "hybrid", "Cascade Hybrid (Cross-Encoder)"),
]

ansi_escape = re.compile(r'\x1b\[[0-9;]*m')


@dataclass
class SearchResult:
    method: str
    strategy: Optional[str]
    query: str
    time_ms: float
    count: int
    top_files: List[str]
    top_scores: List[float]
    success: bool
    error: Optional[str] = None


def run_search(query: str, method: str, strategy: Optional[str] = None, limit: int = 10) -> SearchResult:
    """Run a search and return structured result."""
    cmd = [sys.executable, "-m", "codexlens", "search", query,
           "--method", method, "--limit", str(limit), "--json"]

    if strategy and method == "cascade":
        cmd.extend(["--cascade-strategy", strategy])

    start = time.perf_counter()
    result = subprocess.run(cmd, capture_output=True, text=True, encoding="utf-8")
    elapsed = (time.perf_counter() - start) * 1000

    # Strip ANSI codes
    output = ansi_escape.sub('', result.stdout + result.stderr)

    # Parse JSON
    start_idx = output.find('{')
    if start_idx < 0:
        return SearchResult(
            method=method, strategy=strategy, query=query,
            time_ms=elapsed, count=0, top_files=[], top_scores=[],
            success=False, error="No JSON found"
        )

    # Parse nested JSON properly
    in_string = False
    escaped = False
    depth = 0
    end_idx = start_idx

    for i, c in enumerate(output[start_idx:]):
        if escaped:
            escaped = False
            continue
        if c == '\\':
            escaped = True
            continue
        if c == '"' and not escaped:
            in_string = not in_string
            continue
        if not in_string:
            if c == '{':
                depth += 1
            elif c == '}':
                depth -= 1
                if depth == 0:
                    end_idx = start_idx + i + 1
                    break

    try:
        data = json.loads(output[start_idx:end_idx])
        if not data.get("success"):
            return SearchResult(
                method=method, strategy=strategy, query=query,
                time_ms=elapsed, count=0, top_files=[], top_scores=[],
                success=False, error=data.get("error", "Unknown error")
            )

        results = data.get("result", {}).get("results", [])[:limit]
        stats = data.get("result", {}).get("stats", {})

        top_files = [os.path.basename(r.get("path", "")) for r in results]
        top_scores = [r.get("score", 0) for r in results]

        return SearchResult(
            method=method, strategy=strategy, query=query,
            time_ms=stats.get("time_ms", elapsed),
            count=len(results),
            top_files=top_files,
            top_scores=top_scores,
            success=True
        )
    except Exception as e:
        return SearchResult(
            method=method, strategy=strategy, query=query,
            time_ms=elapsed, count=0, top_files=[], top_scores=[],
            success=False, error=str(e)
        )


def calculate_ranking_similarity(baseline: List[str], candidate: List[str]) -> float:
    """Calculate ranking similarity using normalized DCG."""
    if not baseline or not candidate:
        return 0.0

    # Simple overlap-based similarity with position weighting
    score = 0.0
    for i, file in enumerate(candidate[:10]):
        if file in baseline:
            baseline_pos = baseline.index(file)
            # Weight by position similarity
            pos_diff = abs(i - baseline_pos)
            score += 1.0 / (1 + pos_diff * 0.2)

    return score / min(len(baseline), 10)


def print_divider(char="=", width=80):
    print(char * width)


def main():
    print_divider()
    print("ğŸ”¬ CodexLens æœç´¢æ–¹æ³•å¤šç»´åº¦å¯¹æ¯”æµ‹è¯•")
    print_divider()
    print(f"æµ‹è¯•ç›®å½•: {os.getcwd()}")
    print(f"æµ‹è¯•æŸ¥è¯¢æ•°: {len(TEST_QUERIES)}")
    print(f"å¯¹æ¯”æ–¹æ³•æ•°: {len(SEARCH_METHODS)}")
    print_divider()

    all_results: Dict[str, Dict[str, SearchResult]] = {}

    # Run all tests
    for query, query_desc in TEST_QUERIES:
        print(f"\nğŸ“ æŸ¥è¯¢: \"{query}\" ({query_desc})")
        print("-" * 60)

        all_results[query] = {}

        for method, strategy, method_name in SEARCH_METHODS:
            method_key = f"{method}_{strategy}" if strategy else method
            print(f"  â³ {method_name}...", end=" ", flush=True)

            result = run_search(query, method, strategy)
            all_results[query][method_key] = result

            if result.success:
                print(f"âœ“ {result.time_ms:.0f}ms, {result.count} results")
            else:
                print(f"âœ— {result.error}")

    # === Analysis ===
    print("\n")
    print_divider()
    print("ğŸ“Š ç»¼åˆåˆ†ææŠ¥å‘Š")
    print_divider()

    # 1. Speed Comparison
    print("\n### 1ï¸âƒ£ é€Ÿåº¦å¯¹æ¯” (å¹³å‡è€—æ—¶ ms)")
    print("-" * 60)

    method_times: Dict[str, List[float]] = {f"{m}_{s}" if s else m: [] for m, s, _ in SEARCH_METHODS}

    for query in all_results:
        for method_key, result in all_results[query].items():
            if result.success:
                method_times[method_key].append(result.time_ms)

    speed_ranking = []
    for method, strategy, method_name in SEARCH_METHODS:
        method_key = f"{method}_{strategy}" if strategy else method
        times = method_times[method_key]
        if times:
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            speed_ranking.append((method_name, avg_time, min_time, max_time))

    speed_ranking.sort(key=lambda x: x[1])

    print(f"{'æ–¹æ³•':<35} {'å¹³å‡':>10} {'æœ€å¿«':>10} {'æœ€æ…¢':>10}")
    print("-" * 65)
    for method_name, avg, min_t, max_t in speed_ranking:
        print(f"{method_name:<35} {avg:>10.0f} {min_t:>10.0f} {max_t:>10.0f}")

    # Speed winner
    if speed_ranking:
        fastest = speed_ranking[0]
        slowest = speed_ranking[-1]
        speedup = slowest[1] / fastest[1] if fastest[1] > 0 else 0
        print(f"\nğŸ† æœ€å¿«: {fastest[0]} (æ¯”æœ€æ…¢å¿« {speedup:.1f}x)")

    # 2. Score Distribution
    print("\n### 2ï¸âƒ£ ç›¸å…³æ€§å¾—åˆ†åˆ†å¸ƒ (Top-10 å¹³å‡åˆ†)")
    print("-" * 60)

    method_scores: Dict[str, List[float]] = {f"{m}_{s}" if s else m: [] for m, s, _ in SEARCH_METHODS}

    for query in all_results:
        for method_key, result in all_results[query].items():
            if result.success and result.top_scores:
                avg_score = sum(result.top_scores) / len(result.top_scores)
                method_scores[method_key].append(avg_score)

    print(f"{'æ–¹æ³•':<35} {'å¹³å‡åˆ†':>12} {'åˆ†å¸ƒèŒƒå›´':>20}")
    print("-" * 67)
    for method, strategy, method_name in SEARCH_METHODS:
        method_key = f"{method}_{strategy}" if strategy else method
        scores = method_scores[method_key]
        if scores:
            avg_score = sum(scores) / len(scores)
            min_score = min(scores)
            max_score = max(scores)
            print(f"{method_name:<35} {avg_score:>12.4f} {min_score:.4f} - {max_score:.4f}")

    # 3. Ranking Stability (vs Hybrid as baseline)
    print("\n### 3ï¸âƒ£ æ’åç¨³å®šæ€§ (ä¸ Hybrid åŸºçº¿å¯¹æ¯”)")
    print("-" * 60)

    print(f"{'æ–¹æ³•':<35} {'ç›¸ä¼¼åº¦':>12} {'è¯´æ˜':>20}")
    print("-" * 67)

    for method, strategy, method_name in SEARCH_METHODS:
        method_key = f"{method}_{strategy}" if strategy else method
        if method_key == "hybrid":
            print(f"{method_name:<35} {'1.0000':>12} {'(åŸºçº¿)':>20}")
            continue

        similarities = []
        for query in all_results:
            baseline = all_results[query].get("hybrid")
            candidate = all_results[query].get(method_key)
            if baseline and candidate and baseline.success and candidate.success:
                sim = calculate_ranking_similarity(baseline.top_files, candidate.top_files)
                similarities.append(sim)

        if similarities:
            avg_sim = sum(similarities) / len(similarities)
            diff_level = "é«˜åº¦ä¸€è‡´" if avg_sim > 0.7 else "ä¸­åº¦å·®å¼‚" if avg_sim > 0.4 else "æ˜¾è‘—å·®å¼‚"
            print(f"{method_name:<35} {avg_sim:>12.4f} {diff_level:>20}")

    # 4. Detailed Query Comparison
    print("\n### 4ï¸âƒ£ å„æŸ¥è¯¢è¯¦ç»†å¯¹æ¯”")
    print("-" * 60)

    for query, query_desc in TEST_QUERIES:
        print(f"\nğŸ“Œ \"{query}\" ({query_desc})")
        print()

        # Show top-3 results for each method
        for method, strategy, method_name in SEARCH_METHODS:
            method_key = f"{method}_{strategy}" if strategy else method
            result = all_results[query].get(method_key)

            if result and result.success:
                print(f"  [{method_name}] {result.time_ms:.0f}ms")
                for i, (file, score) in enumerate(zip(result.top_files[:3], result.top_scores[:3]), 1):
                    print(f"    {i}. {file:<40} {score:.4f}")
            else:
                print(f"  [{method_name}] å¤±è´¥: {result.error if result else 'N/A'}")
        print()

    # 5. Summary
    print_divider()
    print("ğŸ“‹ æ€»ç»“")
    print_divider()

    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ–¹æ³•ç‰¹ç‚¹æ€»ç»“                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Hybrid (FTS+Vector)     â”‚ åŸºçº¿æ–¹æ³•ï¼Œç»¼åˆè´¨é‡å¥½ï¼Œé€Ÿåº¦ä¸­ç­‰              â”‚
â”‚ Pure Vector             â”‚ è¯­ä¹‰ç†è§£å¼ºï¼Œé€‚åˆè‡ªç„¶è¯­è¨€æŸ¥è¯¢                â”‚
â”‚ Cascade Binary          â”‚ é€Ÿåº¦æœ€å¿«ï¼Œé€‚åˆå¤§ä»£ç åº“å¿«é€Ÿæ£€ç´¢              â”‚
â”‚ Cascade Hybrid          â”‚ Cross-Encoder ç²¾æ’ï¼Œè´¨é‡æœ€é«˜ä½†é€Ÿåº¦è¾ƒæ…¢       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ¨èä½¿ç”¨åœºæ™¯:
â€¢ æ—¥å¸¸æœç´¢: hybrid (é»˜è®¤)
â€¢ å¤§ä»£ç åº“å¿«é€Ÿæ£€ç´¢: cascade --cascade-strategy binary
â€¢ è¿½æ±‚æœ€é«˜è´¨é‡: cascade --cascade-strategy hybrid
â€¢ è‡ªç„¶è¯­è¨€æŸ¥è¯¢: vector
""")

    print_divider()


if __name__ == "__main__":
    main()
