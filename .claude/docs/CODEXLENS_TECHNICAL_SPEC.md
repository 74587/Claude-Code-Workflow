# CodexLens æŠ€æœ¯æ–¹æ¡ˆ

> èåˆ code-index-mcp ä¸ codanna æœ€ä½³ç‰¹æ€§çš„ä»£ç æ™ºèƒ½åˆ†æå¹³å°
>
> ç›®æ ‡ï¼šæ¥å…¥ CCW (Claude Code Workflow) å·¥å…·ç«¯ç‚¹

---

## ç›®å½•

1. [é¡¹ç›®æ¦‚è§ˆ](#1-é¡¹ç›®æ¦‚è§ˆ)
2. [æ¶æ„è®¾è®¡](#2-æ¶æ„è®¾è®¡)
3. [ç›®å½•ç»“æ„](#3-ç›®å½•ç»“æ„)
4. [æ ¸å¿ƒæ¨¡å—è®¾è®¡](#4-æ ¸å¿ƒæ¨¡å—è®¾è®¡)
5. [CCW é›†æˆè®¾è®¡](#5-ccw-é›†æˆè®¾è®¡)
6. [æ•°æ®å­˜å‚¨è®¾è®¡](#6-æ•°æ®å­˜å‚¨è®¾è®¡)
7. [è¯­ä¹‰æœç´¢æ¶æ„](#7-è¯­ä¹‰æœç´¢æ¶æ„)
8. [CLI å‘½ä»¤è®¾è®¡](#8-cli-å‘½ä»¤è®¾è®¡)
9. [å¼€å‘è·¯çº¿å›¾](#9-å¼€å‘è·¯çº¿å›¾)
10. [æŠ€æœ¯ä¾èµ–](#10-æŠ€æœ¯ä¾èµ–)
11. [npm åˆ†å‘ç­–ç•¥](#11-npm-åˆ†å‘ç­–ç•¥)

---

## 1. é¡¹ç›®æ¦‚è§ˆ

### 1.1 é¡¹ç›®ä¿¡æ¯

| å±æ€§ | å€¼ |
|------|-----|
| **é¡¹ç›®åç§°** | CodexLens |
| **åŒ…å** | `codex_lens` |
| **è¯­è¨€** | Python 3.10+ |
| **å®šä½** | å¤šæ¨¡æ€ä»£ç åˆ†æå¹³å° |
| **é›†æˆç›®æ ‡** | CCW å·¥å…·ç«¯ç‚¹ (`D:\Claude_dms3\ccw`) |

### 1.2 æ ¸å¿ƒèƒ½åŠ›

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CodexLens èƒ½åŠ›çŸ©é˜µ                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ” ç»“æ„ç´¢å¼•     â”‚ AST è§£æã€ç¬¦å·æå–ã€è°ƒç”¨å…³ç³»å›¾            â”‚
â”‚  ğŸ§  è¯­ä¹‰æœç´¢     â”‚ è‡ªç„¶è¯­è¨€æŸ¥è¯¢ã€å‘é‡åµŒå…¥ã€ç›¸ä¼¼åº¦åŒ¹é…        â”‚
â”‚  ğŸ“Š ä»£ç åˆ†æ     â”‚ å¤æ‚åº¦è®¡ç®—ã€å½±å“åˆ†æã€ä¾èµ–è¿½è¸ª            â”‚
â”‚  ğŸ”— CCW é›†æˆ     â”‚ JSON åè®®ã€å·¥å…·æ³¨å†Œã€å‘½ä»¤è¡Œæ¥å£           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 è®¾è®¡åŸåˆ™

- **CLI-First**: æ— æœåŠ¡å™¨ä¾èµ–ï¼Œé€šè¿‡å‘½ä»¤è¡Œè°ƒç”¨
- **JSON åè®®**: æ ‡å‡†åŒ–è¾“å…¥è¾“å‡ºï¼Œä¾¿äº CCW è§£æ
- **å¢é‡ç´¢å¼•**: ä»…å¤„ç†å˜æ›´æ–‡ä»¶ï¼Œæå‡æ€§èƒ½
- **å¯é€‰è¯­ä¹‰**: è¯­ä¹‰æœç´¢ä½œä¸ºå¯é€‰åŠŸèƒ½ï¼Œä¿æŒæ ¸å¿ƒè½»é‡

---

## 2. æ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CCW å±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  ccw/src/tools/codex-lens.js (CCW Tool Wrapper)         â”‚    â”‚
â”‚  â”‚  - æ³¨å†Œ CodexLens å·¥å…·åˆ° CCW                             â”‚    â”‚
â”‚  â”‚  - å‚æ•°éªŒè¯ä¸è½¬æ¢                                        â”‚    â”‚
â”‚  â”‚  - è°ƒç”¨ Python CLI                                       â”‚    â”‚
â”‚  â”‚  - è§£æ JSON è¾“å‡º                                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ spawn / exec
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CodexLens CLI                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  codexlens <command> [options] --json                    â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  Commands:                                               â”‚    â”‚
â”‚  â”‚  - init          åˆå§‹åŒ–é¡¹ç›®ç´¢å¼•                          â”‚    â”‚
â”‚  â”‚  - search        æ–‡æœ¬/æ­£åˆ™æœç´¢                           â”‚    â”‚
â”‚  â”‚  - find          æ–‡ä»¶æŸ¥æ‰¾ (glob)                         â”‚    â”‚
â”‚  â”‚  - symbol        ç¬¦å·æŸ¥æ‰¾                                â”‚    â”‚
â”‚  â”‚  - inspect       æ–‡ä»¶/ç¬¦å·è¯¦æƒ…                           â”‚    â”‚
â”‚  â”‚  - graph         è°ƒç”¨å…³ç³»å›¾                              â”‚    â”‚
â”‚  â”‚  - semantic      è¯­ä¹‰æœç´¢ (å¯é€‰)                         â”‚    â”‚
â”‚  â”‚  - status        ç´¢å¼•çŠ¶æ€                                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Core Engine                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Indexer    â”‚  â”‚   Searcher   â”‚  â”‚   Analyzer   â”‚          â”‚
â”‚  â”‚  (ç´¢å¼•å¼•æ“)   â”‚  â”‚  (æœç´¢å¼•æ“)   â”‚  â”‚  (åˆ†æå¼•æ“)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                 â”‚                 â”‚                   â”‚
â”‚         â–¼                 â–¼                 â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    Storage Layer                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚
â”‚  â”‚  â”‚   SQLite    â”‚  â”‚  ChromaDB   â”‚  â”‚  FileCache  â”‚      â”‚    â”‚
â”‚  â”‚  â”‚ (ç¬¦å·ç´¢å¼•)   â”‚  â”‚ (å‘é‡å­˜å‚¨)   â”‚  â”‚ (æ–‡ä»¶ç¼“å­˜)   â”‚      â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ•°æ®æµ

```
ç”¨æˆ·/CCW è¯·æ±‚
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLI è§£æ   â”‚ â”€â”€â†’ éªŒè¯å‚æ•° â”€â”€â†’ åŠ è½½é…ç½®
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‘½ä»¤è·¯ç”±å™¨  â”‚ â”€â”€â†’ é€‰æ‹©å¤„ç†å™¨
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â†’ SearchHandler â”€â”€â†’ ripgrep/SQLite
       â”œâ”€â”€â†’ SymbolHandler â”€â”€â†’ SQLite ç¬¦å·è¡¨
       â”œâ”€â”€â†’ GraphHandler  â”€â”€â†’ NetworkX å›¾
       â””â”€â”€â†’ SemanticHandler â”€â”€â†’ ChromaDB å‘é‡
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON è¾“å‡º   â”‚ â”€â”€â†’ stdout
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. ç›®å½•ç»“æ„

### 3.1 Python é¡¹ç›®ç»“æ„

```
codex-lens/
â”œâ”€â”€ .codexlens/                   # é¡¹ç›®çº§é…ç½®ç›®å½• (git ignored)
â”‚   â”œâ”€â”€ config.toml               # é¡¹ç›®é…ç½®
â”‚   â”œâ”€â”€ index.db                  # SQLite ç´¢å¼•
â”‚   â””â”€â”€ vectors/                  # ChromaDB å‘é‡å­˜å‚¨
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ codex_lens/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ __main__.py           # python -m codex_lens å…¥å£
â”‚       â”‚
â”‚       â”œâ”€â”€ cli/                  # CLI å±‚
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ main.py           # Typer åº”ç”¨ä¸»å…¥å£
â”‚       â”‚   â”œâ”€â”€ commands/         # å‘½ä»¤å®ç°
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚   â”œâ”€â”€ init.py       # codexlens init
â”‚       â”‚   â”‚   â”œâ”€â”€ search.py     # codexlens search
â”‚       â”‚   â”‚   â”œâ”€â”€ find.py       # codexlens find
â”‚       â”‚   â”‚   â”œâ”€â”€ symbol.py     # codexlens symbol
â”‚       â”‚   â”‚   â”œâ”€â”€ inspect.py    # codexlens inspect
â”‚       â”‚   â”‚   â”œâ”€â”€ graph.py      # codexlens graph
â”‚       â”‚   â”‚   â”œâ”€â”€ semantic.py   # codexlens semantic
â”‚       â”‚   â”‚   â””â”€â”€ status.py     # codexlens status
â”‚       â”‚   â””â”€â”€ output.py         # JSON è¾“å‡ºæ ¼å¼åŒ–
â”‚       â”‚
â”‚       â”œâ”€â”€ core/                 # æ ¸å¿ƒé¢†åŸŸå±‚
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ entities.py       # æ•°æ®å®ä½“: Symbol, File, Relation
â”‚       â”‚   â”œâ”€â”€ interfaces.py     # æŠ½è±¡æ¥å£: Indexer, Searcher
â”‚       â”‚   â”œâ”€â”€ config.py         # Pydantic é…ç½®æ¨¡å‹
â”‚       â”‚   â””â”€â”€ errors.py         # è‡ªå®šä¹‰å¼‚å¸¸
â”‚       â”‚
â”‚       â”œâ”€â”€ engine/               # å¼•æ“å±‚
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ indexer.py        # ç´¢å¼•ç¼–æ’å™¨
â”‚       â”‚   â”œâ”€â”€ searcher.py       # æœç´¢ç¼–æ’å™¨
â”‚       â”‚   â”œâ”€â”€ analyzer.py       # åˆ†æç¼–æ’å™¨
â”‚       â”‚   â””â”€â”€ watcher.py        # æ–‡ä»¶ç›‘æ§ (å¯é€‰)
â”‚       â”‚
â”‚       â”œâ”€â”€ parsing/              # è§£æå±‚
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py           # ParsingStrategy ABC
â”‚       â”‚   â”œâ”€â”€ factory.py        # ç­–ç•¥å·¥å‚
â”‚       â”‚   â”œâ”€â”€ python_parser.py  # Python AST è§£æ
â”‚       â”‚   â”œâ”€â”€ js_parser.py      # JavaScript/TS è§£æ
â”‚       â”‚   â”œâ”€â”€ rust_parser.py    # Rust è§£æ
â”‚       â”‚   â””â”€â”€ fallback.py       # é€šç”¨å›é€€è§£æ
â”‚       â”‚
â”‚       â”œâ”€â”€ semantic/             # è¯­ä¹‰æœç´¢å±‚ (å¯é€‰)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ embedder.py       # åµŒå…¥ç”Ÿæˆå™¨
â”‚       â”‚   â”œâ”€â”€ chunker.py        # ä»£ç åˆ†å—
â”‚       â”‚   â””â”€â”€ search.py         # å‘é‡æœç´¢
â”‚       â”‚
â”‚       â”œâ”€â”€ storage/              # å­˜å‚¨å±‚
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ sqlite_store.py   # SQLite å­˜å‚¨
â”‚       â”‚   â”œâ”€â”€ vector_store.py   # ChromaDB é€‚é…
â”‚       â”‚   â””â”€â”€ file_cache.py     # æ–‡ä»¶å“ˆå¸Œç¼“å­˜
â”‚       â”‚
â”‚       â””â”€â”€ utils/                # å·¥å…·å±‚
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ git.py            # Git é›†æˆ
â”‚           â”œâ”€â”€ ripgrep.py        # ripgrep åŒ…è£…
â”‚           â””â”€â”€ logging.py        # æ—¥å¿—é…ç½®
â”‚
â”œâ”€â”€ tests/                        # æµ‹è¯•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_indexer.py
â”‚   â”œâ”€â”€ test_search.py
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ pyproject.toml                # é¡¹ç›®é…ç½®
â”œâ”€â”€ codexlens.spec                # PyInstaller é…ç½®
â””â”€â”€ README.md
```

### 3.2 CCW é›†æˆæ–‡ä»¶

```
D:\Claude_dms3\ccw\src\tools\
â””â”€â”€ codex-lens.js                 # CCW å·¥å…·åŒ…è£…å™¨
```

---

## 4. æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 4.1 æ ¸å¿ƒå®ä½“ (`core/entities.py`)

```python
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any
from enum import Enum

class SymbolType(Enum):
    FUNCTION = "function"
    CLASS = "class"
    METHOD = "method"
    VARIABLE = "variable"
    INTERFACE = "interface"
    MODULE = "module"
    IMPORT = "import"

class RelationType(Enum):
    CALLS = "calls"
    CALLED_BY = "called_by"
    IMPORTS = "imports"
    IMPORTED_BY = "imported_by"
    EXTENDS = "extends"
    IMPLEMENTS = "implements"

@dataclass
class Location:
    """ä»£ç ä½ç½®"""
    file_path: str
    line_start: int
    line_end: int
    column_start: int = 0
    column_end: int = 0

@dataclass
class Symbol:
    """ä»£ç ç¬¦å·"""
    id: str                           # å”¯ä¸€æ ‡è¯†: file_path::name
    name: str                         # ç¬¦å·åç§°
    short_name: str                   # çŸ­åç§° (ç”¨äºæ¨¡ç³ŠåŒ¹é…)
    type: SymbolType                  # ç¬¦å·ç±»å‹
    location: Location                # ä½ç½®ä¿¡æ¯
    signature: Optional[str] = None   # å‡½æ•°ç­¾å
    docstring: Optional[str] = None   # æ–‡æ¡£å­—ç¬¦ä¸²
    language: str = "unknown"         # è¯­è¨€
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class FileInfo:
    """æ–‡ä»¶ä¿¡æ¯"""
    path: str                         # ç›¸å¯¹è·¯å¾„
    language: str                     # è¯­è¨€
    line_count: int                   # è¡Œæ•°
    hash: str                         # å†…å®¹å“ˆå¸Œ (ç”¨äºå¢é‡ç´¢å¼•)
    imports: List[str] = field(default_factory=list)
    exports: List[str] = field(default_factory=list)
    symbols: List[str] = field(default_factory=list)  # symbol_ids

@dataclass
class Relation:
    """ç¬¦å·å…³ç³»"""
    source_id: str                    # æºç¬¦å· ID
    target_id: str                    # ç›®æ ‡ç¬¦å· ID
    relation_type: RelationType       # å…³ç³»ç±»å‹
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class SearchResult:
    """æœç´¢ç»“æœ"""
    file_path: str
    line: int
    column: int
    content: str
    context_before: List[str] = field(default_factory=list)
    context_after: List[str] = field(default_factory=list)
    score: float = 1.0                # ç›¸å…³æ€§å¾—åˆ†
```

### 4.2 é…ç½®æ¨¡å‹ (`core/config.py`)

```python
from pydantic import BaseModel, Field
from typing import List, Optional
from pathlib import Path

class IndexConfig(BaseModel):
    """ç´¢å¼•é…ç½®"""
    include_patterns: List[str] = Field(
        default=["**/*.py", "**/*.js", "**/*.ts", "**/*.rs"],
        description="åŒ…å«çš„æ–‡ä»¶æ¨¡å¼"
    )
    exclude_patterns: List[str] = Field(
        default=["**/node_modules/**", "**/.git/**", "**/dist/**", "**/__pycache__/**"],
        description="æ’é™¤çš„æ–‡ä»¶æ¨¡å¼"
    )
    max_file_size: int = Field(
        default=1024 * 1024,  # 1MB
        description="æœ€å¤§æ–‡ä»¶å¤§å° (bytes)"
    )
    enable_semantic: bool = Field(
        default=False,
        description="å¯ç”¨è¯­ä¹‰æœç´¢"
    )

class SemanticConfig(BaseModel):
    """è¯­ä¹‰æœç´¢é…ç½®"""
    model_name: str = Field(
        default="all-MiniLM-L6-v2",
        description="åµŒå…¥æ¨¡å‹åç§°"
    )
    chunk_size: int = Field(
        default=512,
        description="ä»£ç å—å¤§å° (tokens)"
    )
    chunk_overlap: int = Field(
        default=50,
        description="å—é‡å å¤§å°"
    )

class ProjectConfig(BaseModel):
    """é¡¹ç›®é…ç½®"""
    project_root: Path
    index: IndexConfig = Field(default_factory=IndexConfig)
    semantic: SemanticConfig = Field(default_factory=SemanticConfig)

    @classmethod
    def load(cls, config_path: Path) -> "ProjectConfig":
        """ä»é…ç½®æ–‡ä»¶åŠ è½½"""
        import tomli
        with open(config_path, "rb") as f:
            data = tomli.load(f)
        return cls(**data)

    def save(self, config_path: Path):
        """ä¿å­˜åˆ°é…ç½®æ–‡ä»¶"""
        import tomli_w
        with open(config_path, "wb") as f:
            tomli_w.dump(self.model_dump(), f)
```

### 4.3 è§£æç­–ç•¥æ¥å£ (`parsing/base.py`)

```python
from abc import ABC, abstractmethod
from typing import List, Tuple, Dict, Any
from ..core.entities import Symbol, FileInfo

class ParsingStrategy(ABC):
    """è¯­è¨€è§£æç­–ç•¥åŸºç±»"""

    @abstractmethod
    def get_language_name(self) -> str:
        """è¿”å›è¯­è¨€åç§°"""
        pass

    @abstractmethod
    def get_supported_extensions(self) -> List[str]:
        """è¿”å›æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å"""
        pass

    @abstractmethod
    def parse_file(
        self,
        file_path: str,
        content: str
    ) -> Tuple[List[Symbol], FileInfo, List[Dict[str, Any]]]:
        """
        è§£ææ–‡ä»¶

        Returns:
            - symbols: æå–çš„ç¬¦å·åˆ—è¡¨
            - file_info: æ–‡ä»¶ä¿¡æ¯
            - pending_calls: å¾…è§£æçš„è°ƒç”¨å…³ç³»
        """
        pass

    def supports_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¯æŒè¯¥æ–‡ä»¶"""
        ext = file_path.rsplit(".", 1)[-1] if "." in file_path else ""
        return f".{ext}" in self.get_supported_extensions()
```

### 4.4 ç´¢å¼•å¼•æ“ (`engine/indexer.py`)

```python
import hashlib
from pathlib import Path
from typing import List, Optional, Generator
from concurrent.futures import ThreadPoolExecutor, as_completed

from ..core.config import ProjectConfig
from ..core.entities import Symbol, FileInfo, Relation
from ..parsing.factory import ParserFactory
from ..storage.sqlite_store import SQLiteStore
from ..storage.file_cache import FileCache
from ..utils.git import get_git_files

class Indexer:
    """ç´¢å¼•å¼•æ“"""

    def __init__(self, config: ProjectConfig):
        self.config = config
        self.store = SQLiteStore(config.project_root / ".codexlens" / "index.db")
        self.cache = FileCache(config.project_root / ".codexlens" / "cache.json")
        self.parser_factory = ParserFactory()

    def build_index(self, incremental: bool = True) -> dict:
        """
        æ„å»ºç´¢å¼•

        Args:
            incremental: æ˜¯å¦å¢é‡ç´¢å¼•

        Returns:
            ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {
            "files_scanned": 0,
            "files_indexed": 0,
            "files_skipped": 0,
            "symbols_extracted": 0,
            "relations_resolved": 0,
            "errors": []
        }

        # 1. å‘ç°æ–‡ä»¶
        files = list(self._discover_files())
        stats["files_scanned"] = len(files)

        # 2. è¿‡æ»¤éœ€è¦é‡æ–°ç´¢å¼•çš„æ–‡ä»¶
        if incremental:
            files = self._filter_changed_files(files)

        # 3. å¹¶è¡Œè§£æ
        pending_calls = []
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {
                executor.submit(self._parse_file, f): f
                for f in files
            }

            for future in as_completed(futures):
                file_path = futures[future]
                try:
                    symbols, file_info, calls = future.result()

                    # å­˜å‚¨æ–‡ä»¶ä¿¡æ¯
                    self.store.upsert_file(file_info)

                    # å­˜å‚¨ç¬¦å·
                    for symbol in symbols:
                        self.store.upsert_symbol(symbol)
                        stats["symbols_extracted"] += 1

                    # æ”¶é›†å¾…è§£æè°ƒç”¨
                    pending_calls.extend(calls)

                    # æ›´æ–°ç¼“å­˜
                    self.cache.update(file_path, file_info.hash)
                    stats["files_indexed"] += 1

                except Exception as e:
                    stats["errors"].append({
                        "file": file_path,
                        "error": str(e)
                    })

        # 4. è§£æè°ƒç”¨å…³ç³»
        stats["relations_resolved"] = self._resolve_calls(pending_calls)

        # 5. ä¿å­˜ç¼“å­˜
        self.cache.save()

        return stats

    def _discover_files(self) -> Generator[str, None, None]:
        """å‘ç°é¡¹ç›®æ–‡ä»¶"""
        # ä¼˜å…ˆä½¿ç”¨ git ls-files
        git_files = get_git_files(self.config.project_root)
        if git_files:
            for f in git_files:
                if self._should_include(f):
                    yield f
        else:
            # å›é€€åˆ° glob
            for pattern in self.config.index.include_patterns:
                for f in self.config.project_root.glob(pattern):
                    if self._should_include(str(f)):
                        yield str(f.relative_to(self.config.project_root))

    def _should_include(self, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«ç´¢å¼•"""
        from fnmatch import fnmatch
        for pattern in self.config.index.exclude_patterns:
            if fnmatch(file_path, pattern):
                return False
        return True

    def _filter_changed_files(self, files: List[str]) -> List[str]:
        """è¿‡æ»¤å‡ºå˜æ›´çš„æ–‡ä»¶"""
        changed = []
        for f in files:
            full_path = self.config.project_root / f
            current_hash = self._compute_hash(full_path)
            cached_hash = self.cache.get(f)
            if current_hash != cached_hash:
                changed.append(f)
        return changed

    def _compute_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
        with open(file_path, "rb") as f:
            return hashlib.md5(f.read()).hexdigest()

    def _parse_file(self, file_path: str):
        """è§£æå•ä¸ªæ–‡ä»¶"""
        full_path = self.config.project_root / file_path
        content = full_path.read_text(encoding="utf-8", errors="ignore")

        parser = self.parser_factory.get_parser(file_path)
        return parser.parse_file(file_path, content)

    def _resolve_calls(self, pending_calls: List[dict]) -> int:
        """è§£æè°ƒç”¨å…³ç³»"""
        resolved = 0
        for call in pending_calls:
            caller_id = call["caller_id"]
            callee_name = call["callee_name"]

            # æŸ¥æ‰¾è¢«è°ƒç”¨ç¬¦å·
            callee = self.store.find_symbol_by_name(callee_name)
            if callee:
                relation = Relation(
                    source_id=caller_id,
                    target_id=callee.id,
                    relation_type="calls"
                )
                self.store.upsert_relation(relation)
                resolved += 1

        return resolved
```

---

## 5. CCW é›†æˆè®¾è®¡

### 5.1 JSON è¾“å‡ºåè®®

æ‰€æœ‰ CLI å‘½ä»¤ä½¿ç”¨ `--json` æ ‡å¿—è¾“å‡ºæ ‡å‡†åŒ– JSONã€‚

**æˆåŠŸå“åº”**:
```json
{
  "success": true,
  "data": {
    "results": [...],
    "metadata": {
      "count": 10,
      "elapsed_ms": 45,
      "mode": "exact"
    }
  }
}
```

**é”™è¯¯å“åº”**:
```json
{
  "success": false,
  "error": {
    "code": "INDEX_NOT_FOUND",
    "message": "Project not initialized. Run 'codexlens init' first.",
    "suggestion": "codexlens init /path/to/project"
  }
}
```

### 5.2 CCW å·¥å…·åŒ…è£…å™¨ (`ccw/src/tools/codex-lens.js`)

```javascript
/**
 * CodexLens Tool - Code Intelligence Integration for CCW
 *
 * Provides:
 * - Symbol search and navigation
 * - Semantic code search
 * - Dependency graph analysis
 * - File inspection
 */

import { spawn } from 'child_process';
import { existsSync } from 'fs';
import { resolve } from 'path';

// CodexLens binary path (configurable)
const CODEXLENS_BIN = process.env.CODEXLENS_BIN || 'codexlens';

/**
 * Execute CodexLens CLI command
 * @param {string[]} args - Command arguments
 * @param {string} cwd - Working directory
 * @returns {Promise<Object>} - Parsed JSON result
 */
async function execCodexLens(args, cwd = process.cwd()) {
  return new Promise((resolve, reject) => {
    const child = spawn(CODEXLENS_BIN, [...args, '--json'], {
      cwd,
      stdio: ['ignore', 'pipe', 'pipe']
    });

    let stdout = '';
    let stderr = '';

    child.stdout.on('data', (data) => { stdout += data.toString(); });
    child.stderr.on('data', (data) => { stderr += data.toString(); });

    child.on('close', (code) => {
      try {
        const result = JSON.parse(stdout);
        resolve(result);
      } catch (err) {
        reject(new Error(`Failed to parse CodexLens output: ${stderr || stdout}`));
      }
    });

    child.on('error', (err) => {
      reject(new Error(`Failed to execute CodexLens: ${err.message}`));
    });
  });
}

/**
 * Main execute function
 */
async function execute(params) {
  const {
    command,
    query,
    path,
    mode = 'auto',
    limit = 50,
    contextLines = 2,
    includeRelations = false,
    projectPath = process.cwd()
  } = params;

  // Validate command
  const validCommands = ['search', 'find', 'symbol', 'inspect', 'graph', 'semantic', 'status', 'init'];
  if (!validCommands.includes(command)) {
    throw new Error(`Invalid command: ${command}. Valid: ${validCommands.join(', ')}`);
  }

  // Build arguments based on command
  const args = [command];

  switch (command) {
    case 'init':
      args.push(projectPath);
      break;

    case 'search':
      if (!query) throw new Error('Parameter "query" required for search');
      args.push(query);
      if (path) args.push('--path', path);
      args.push('--context', contextLines.toString());
      args.push('--limit', limit.toString());
      break;

    case 'find':
      if (!query) throw new Error('Parameter "query" (glob pattern) required for find');
      args.push(query);
      args.push('--limit', limit.toString());
      break;

    case 'symbol':
      if (!query) throw new Error('Parameter "query" (symbol name) required');
      args.push(query);
      args.push('--mode', mode);  // exact, fuzzy
      args.push('--limit', limit.toString());
      if (includeRelations) args.push('--relations');
      break;

    case 'inspect':
      if (!path) throw new Error('Parameter "path" required for inspect');
      args.push(path);
      break;

    case 'graph':
      if (!query) throw new Error('Parameter "query" (symbol name) required for graph');
      args.push(query);
      args.push('--depth', (params.depth || 2).toString());
      args.push('--direction', params.direction || 'both');  // callers, callees, both
      break;

    case 'semantic':
      if (!query) throw new Error('Parameter "query" required for semantic search');
      args.push(query);
      args.push('--limit', limit.toString());
      break;

    case 'status':
      // No additional args
      break;
  }

  // Execute command
  const result = await execCodexLens(args, projectPath);

  // Transform result for CCW consumption
  return {
    command,
    ...result,
    metadata: {
      ...result.metadata,
      tool: 'codex_lens',
      projectPath
    }
  };
}

/**
 * Tool Definition for CCW Registry
 */
export const codexLensTool = {
  name: 'codex_lens',
  description: `Code intelligence tool for symbol search, semantic search, and dependency analysis.

Commands:
- init: Initialize project index
- search: Text/regex code search (ripgrep backend)
- find: File path search (glob patterns)
- symbol: Symbol name lookup with optional relations
- inspect: Get file/symbol details
- graph: Dependency graph traversal
- semantic: Natural language code search
- status: Index status and statistics

Examples:
- Search for function: codex_lens symbol "handleRequest"
- Find files: codex_lens find "**/*.test.ts"
- Semantic search: codex_lens semantic "authentication middleware"
- Get callers: codex_lens graph "UserService.login" --direction callers`,

  parameters: {
    type: 'object',
    properties: {
      command: {
        type: 'string',
        enum: ['init', 'search', 'find', 'symbol', 'inspect', 'graph', 'semantic', 'status'],
        description: 'CodexLens command to execute'
      },
      query: {
        type: 'string',
        description: 'Search query (text, pattern, or natural language)'
      },
      path: {
        type: 'string',
        description: 'File path or glob pattern'
      },
      mode: {
        type: 'string',
        enum: ['exact', 'fuzzy', 'regex'],
        description: 'Search mode (default: exact)',
        default: 'exact'
      },
      limit: {
        type: 'number',
        description: 'Maximum results (default: 50)',
        default: 50
      },
      contextLines: {
        type: 'number',
        description: 'Context lines around matches (default: 2)',
        default: 2
      },
      depth: {
        type: 'number',
        description: 'Graph traversal depth (default: 2)',
        default: 2
      },
      direction: {
        type: 'string',
        enum: ['callers', 'callees', 'both'],
        description: 'Graph direction (default: both)',
        default: 'both'
      },
      includeRelations: {
        type: 'boolean',
        description: 'Include symbol relations in results',
        default: false
      },
      projectPath: {
        type: 'string',
        description: 'Project root path (default: cwd)'
      }
    },
    required: ['command']
  },
  execute
};
```

### 5.3 æ³¨å†Œåˆ° CCW

åœ¨ `ccw/src/tools/index.js` ä¸­æ·»åŠ :

```javascript
import { codexLensTool } from './codex-lens.js';

// ... ç°æœ‰ imports ...

// Register CodexLens tool
registerTool(codexLensTool);
```

---

## 6. æ•°æ®å­˜å‚¨è®¾è®¡

### 6.1 SQLite Schema

```sql
-- ç‰ˆæœ¬æ§åˆ¶
CREATE TABLE IF NOT EXISTS schema_version (
    version INTEGER PRIMARY KEY,
    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ–‡ä»¶è¡¨
CREATE TABLE IF NOT EXISTS files (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    path TEXT UNIQUE NOT NULL,
    language TEXT NOT NULL,
    line_count INTEGER DEFAULT 0,
    hash TEXT NOT NULL,
    imports TEXT DEFAULT '[]',      -- JSON array
    exports TEXT DEFAULT '[]',      -- JSON array
    indexed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_files_language (language),
    INDEX idx_files_hash (hash)
);

-- ç¬¦å·è¡¨
CREATE TABLE IF NOT EXISTS symbols (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    symbol_id TEXT UNIQUE NOT NULL,      -- file_path::name
    file_id INTEGER NOT NULL REFERENCES files(id) ON DELETE CASCADE,
    name TEXT NOT NULL,
    short_name TEXT NOT NULL,            -- ç”¨äºæ¨¡ç³Šæœç´¢
    type TEXT NOT NULL,                  -- function, class, method, etc.
    line_start INTEGER NOT NULL,
    line_end INTEGER NOT NULL,
    column_start INTEGER DEFAULT 0,
    column_end INTEGER DEFAULT 0,
    signature TEXT,
    docstring TEXT,
    language TEXT NOT NULL,
    metadata TEXT DEFAULT '{}',          -- JSON object

    INDEX idx_symbols_name (name),
    INDEX idx_symbols_short_name (short_name),
    INDEX idx_symbols_type (type),
    INDEX idx_symbols_file_id (file_id)
);

-- å…³ç³»è¡¨
CREATE TABLE IF NOT EXISTS relations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT NOT NULL,             -- symbol_id
    target_id TEXT NOT NULL,             -- symbol_id
    relation_type TEXT NOT NULL,         -- calls, imports, extends, etc.
    metadata TEXT DEFAULT '{}',          -- JSON object

    UNIQUE(source_id, target_id, relation_type),
    INDEX idx_relations_source (source_id),
    INDEX idx_relations_target (target_id),
    INDEX idx_relations_type (relation_type)
);

-- FTS5 å…¨æ–‡æœç´¢ç´¢å¼•
CREATE VIRTUAL TABLE IF NOT EXISTS symbols_fts USING fts5(
    symbol_id,
    name,
    short_name,
    signature,
    docstring,
    content='symbols',
    content_rowid='id'
);

-- è§¦å‘å™¨ï¼šä¿æŒ FTS ç´¢å¼•åŒæ­¥
CREATE TRIGGER symbols_ai AFTER INSERT ON symbols BEGIN
    INSERT INTO symbols_fts(rowid, symbol_id, name, short_name, signature, docstring)
    VALUES (new.id, new.symbol_id, new.name, new.short_name, new.signature, new.docstring);
END;

CREATE TRIGGER symbols_ad AFTER DELETE ON symbols BEGIN
    INSERT INTO symbols_fts(symbols_fts, rowid, symbol_id, name, short_name, signature, docstring)
    VALUES('delete', old.id, old.symbol_id, old.name, old.short_name, old.signature, old.docstring);
END;

CREATE TRIGGER symbols_au AFTER UPDATE ON symbols BEGIN
    INSERT INTO symbols_fts(symbols_fts, rowid, symbol_id, name, short_name, signature, docstring)
    VALUES('delete', old.id, old.symbol_id, old.name, old.short_name, old.signature, old.docstring);
    INSERT INTO symbols_fts(rowid, symbol_id, name, short_name, signature, docstring)
    VALUES (new.id, new.symbol_id, new.name, new.short_name, new.signature, new.docstring);
END;
```

### 6.2 SQLite Store å®ç° (`storage/sqlite_store.py`)

```python
import sqlite3
import json
from pathlib import Path
from typing import List, Optional
from contextlib import contextmanager

from ..core.entities import Symbol, FileInfo, Relation, SymbolType

SCHEMA_VERSION = 1

class SQLiteStore:
    """SQLite å­˜å‚¨ç®¡ç†å™¨"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_schema()

    @contextmanager
    def _connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        conn.execute("PRAGMA foreign_keys = ON")
        conn.execute("PRAGMA journal_mode = WAL")
        try:
            yield conn
            conn.commit()
        finally:
            conn.close()

    def _init_schema(self):
        """åˆå§‹åŒ–æ•°æ®åº“ schema"""
        with self._connection() as conn:
            # æ£€æŸ¥ç‰ˆæœ¬
            conn.execute("""
                CREATE TABLE IF NOT EXISTS schema_version (
                    version INTEGER PRIMARY KEY
                )
            """)

            row = conn.execute("SELECT version FROM schema_version").fetchone()
            current_version = row["version"] if row else 0

            if current_version < SCHEMA_VERSION:
                self._apply_schema(conn)
                conn.execute(
                    "INSERT OR REPLACE INTO schema_version (version) VALUES (?)",
                    (SCHEMA_VERSION,)
                )

    def _apply_schema(self, conn):
        """åº”ç”¨ schema"""
        conn.executescript("""
            CREATE TABLE IF NOT EXISTS files (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                path TEXT UNIQUE NOT NULL,
                language TEXT NOT NULL,
                line_count INTEGER DEFAULT 0,
                hash TEXT NOT NULL,
                imports TEXT DEFAULT '[]',
                exports TEXT DEFAULT '[]',
                indexed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );

            CREATE TABLE IF NOT EXISTS symbols (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol_id TEXT UNIQUE NOT NULL,
                file_id INTEGER NOT NULL REFERENCES files(id) ON DELETE CASCADE,
                name TEXT NOT NULL,
                short_name TEXT NOT NULL,
                type TEXT NOT NULL,
                line_start INTEGER NOT NULL,
                line_end INTEGER NOT NULL,
                column_start INTEGER DEFAULT 0,
                column_end INTEGER DEFAULT 0,
                signature TEXT,
                docstring TEXT,
                language TEXT NOT NULL,
                metadata TEXT DEFAULT '{}'
            );

            CREATE TABLE IF NOT EXISTS relations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_id TEXT NOT NULL,
                target_id TEXT NOT NULL,
                relation_type TEXT NOT NULL,
                metadata TEXT DEFAULT '{}',
                UNIQUE(source_id, target_id, relation_type)
            );

            CREATE INDEX IF NOT EXISTS idx_symbols_name ON symbols(name);
            CREATE INDEX IF NOT EXISTS idx_symbols_short_name ON symbols(short_name);
            CREATE INDEX IF NOT EXISTS idx_symbols_type ON symbols(type);
            CREATE INDEX IF NOT EXISTS idx_relations_source ON relations(source_id);
            CREATE INDEX IF NOT EXISTS idx_relations_target ON relations(target_id);
        """)

    def upsert_file(self, file_info: FileInfo) -> int:
        """æ’å…¥æˆ–æ›´æ–°æ–‡ä»¶"""
        with self._connection() as conn:
            cursor = conn.execute("""
                INSERT INTO files (path, language, line_count, hash, imports, exports)
                VALUES (?, ?, ?, ?, ?, ?)
                ON CONFLICT(path) DO UPDATE SET
                    language = excluded.language,
                    line_count = excluded.line_count,
                    hash = excluded.hash,
                    imports = excluded.imports,
                    exports = excluded.exports,
                    indexed_at = CURRENT_TIMESTAMP
                RETURNING id
            """, (
                file_info.path,
                file_info.language,
                file_info.line_count,
                file_info.hash,
                json.dumps(file_info.imports),
                json.dumps(file_info.exports)
            ))
            return cursor.fetchone()["id"]

    def upsert_symbol(self, symbol: Symbol) -> int:
        """æ’å…¥æˆ–æ›´æ–°ç¬¦å·"""
        with self._connection() as conn:
            # è·å– file_id
            file_row = conn.execute(
                "SELECT id FROM files WHERE path = ?",
                (symbol.location.file_path,)
            ).fetchone()

            if not file_row:
                raise ValueError(f"File not found: {symbol.location.file_path}")

            cursor = conn.execute("""
                INSERT INTO symbols (
                    symbol_id, file_id, name, short_name, type,
                    line_start, line_end, column_start, column_end,
                    signature, docstring, language, metadata
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ON CONFLICT(symbol_id) DO UPDATE SET
                    name = excluded.name,
                    short_name = excluded.short_name,
                    type = excluded.type,
                    line_start = excluded.line_start,
                    line_end = excluded.line_end,
                    signature = excluded.signature,
                    docstring = excluded.docstring,
                    metadata = excluded.metadata
                RETURNING id
            """, (
                symbol.id,
                file_row["id"],
                symbol.name,
                symbol.short_name,
                symbol.type.value,
                symbol.location.line_start,
                symbol.location.line_end,
                symbol.location.column_start,
                symbol.location.column_end,
                symbol.signature,
                symbol.docstring,
                symbol.language,
                json.dumps(symbol.metadata)
            ))
            return cursor.fetchone()["id"]

    def find_symbol_by_name(
        self,
        name: str,
        exact: bool = False
    ) -> Optional[Symbol]:
        """æŒ‰åç§°æŸ¥æ‰¾ç¬¦å·"""
        with self._connection() as conn:
            if exact:
                row = conn.execute(
                    "SELECT * FROM symbols WHERE name = ?",
                    (name,)
                ).fetchone()
            else:
                row = conn.execute(
                    "SELECT * FROM symbols WHERE short_name LIKE ?",
                    (f"%{name}%",)
                ).fetchone()

            return self._row_to_symbol(row) if row else None

    def search_symbols(
        self,
        query: str,
        limit: int = 50
    ) -> List[Symbol]:
        """æœç´¢ç¬¦å·"""
        with self._connection() as conn:
            rows = conn.execute("""
                SELECT * FROM symbols
                WHERE name LIKE ? OR short_name LIKE ? OR signature LIKE ?
                LIMIT ?
            """, (f"%{query}%", f"%{query}%", f"%{query}%", limit)).fetchall()

            return [self._row_to_symbol(row) for row in rows]

    def get_relations(
        self,
        symbol_id: str,
        direction: str = "both"
    ) -> List[Relation]:
        """è·å–ç¬¦å·å…³ç³»"""
        with self._connection() as conn:
            relations = []

            if direction in ("both", "outgoing"):
                rows = conn.execute(
                    "SELECT * FROM relations WHERE source_id = ?",
                    (symbol_id,)
                ).fetchall()
                relations.extend([self._row_to_relation(r) for r in rows])

            if direction in ("both", "incoming"):
                rows = conn.execute(
                    "SELECT * FROM relations WHERE target_id = ?",
                    (symbol_id,)
                ).fetchall()
                relations.extend([self._row_to_relation(r) for r in rows])

            return relations

    def get_stats(self) -> dict:
        """è·å–ç´¢å¼•ç»Ÿè®¡"""
        with self._connection() as conn:
            file_count = conn.execute("SELECT COUNT(*) FROM files").fetchone()[0]
            symbol_count = conn.execute("SELECT COUNT(*) FROM symbols").fetchone()[0]
            relation_count = conn.execute("SELECT COUNT(*) FROM relations").fetchone()[0]

            languages = conn.execute("""
                SELECT language, COUNT(*) as count
                FROM files GROUP BY language
            """).fetchall()

            return {
                "files": file_count,
                "symbols": symbol_count,
                "relations": relation_count,
                "languages": {r["language"]: r["count"] for r in languages}
            }

    def _row_to_symbol(self, row) -> Symbol:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸º Symbol"""
        return Symbol(
            id=row["symbol_id"],
            name=row["name"],
            short_name=row["short_name"],
            type=SymbolType(row["type"]),
            location=Location(
                file_path=row["path"] if "path" in row.keys() else "",
                line_start=row["line_start"],
                line_end=row["line_end"],
                column_start=row["column_start"],
                column_end=row["column_end"]
            ),
            signature=row["signature"],
            docstring=row["docstring"],
            language=row["language"],
            metadata=json.loads(row["metadata"])
        )

    def _row_to_relation(self, row) -> Relation:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸º Relation"""
        return Relation(
            source_id=row["source_id"],
            target_id=row["target_id"],
            relation_type=row["relation_type"],
            metadata=json.loads(row["metadata"])
        )
```

---

## 7. è¯­ä¹‰æœç´¢æ¶æ„

### 7.1 åµŒå…¥ç”Ÿæˆå™¨ (`semantic/embedder.py`)

```python
from typing import List, Optional
from functools import lru_cache

class SemanticEmbedder:
    """è¯­ä¹‰åµŒå…¥ç”Ÿæˆå™¨ (æ‡’åŠ è½½)"""

    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model_name = model_name
        self._model = None

    @property
    def model(self):
        """æ‡’åŠ è½½æ¨¡å‹"""
        if self._model is None:
            from sentence_transformers import SentenceTransformer
            self._model = SentenceTransformer(self.model_name)
        return self._model

    def embed(self, text: str) -> List[float]:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„åµŒå…¥"""
        return self.model.encode(text).tolist()

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”ŸæˆåµŒå…¥"""
        return self.model.encode(texts).tolist()

    def embed_symbol(self, symbol) -> List[float]:
        """ä¸ºç¬¦å·ç”ŸæˆåµŒå…¥"""
        text = self._build_semantic_text(symbol)
        return self.embed(text)

    def _build_semantic_text(self, symbol) -> str:
        """æ„å»ºç¬¦å·çš„è¯­ä¹‰æ–‡æœ¬"""
        parts = [
            f"[{symbol.type.value}] {symbol.name}",
        ]

        if symbol.signature:
            parts.append(f"Signature: {symbol.signature}")

        if symbol.docstring:
            parts.append(f"Description: {symbol.docstring}")

        return "\n".join(parts)
```

### 7.2 å‘é‡å­˜å‚¨ (`semantic/vector_store.py`)

```python
from typing import List, Dict, Any, Optional
from pathlib import Path

class VectorStore:
    """ChromaDB å‘é‡å­˜å‚¨é€‚é…å™¨"""

    def __init__(self, persist_dir: Path):
        self.persist_dir = persist_dir
        self._client = None
        self._collection = None

    @property
    def client(self):
        """æ‡’åŠ è½½ ChromaDB å®¢æˆ·ç«¯"""
        if self._client is None:
            import chromadb
            self._client = chromadb.PersistentClient(
                path=str(self.persist_dir)
            )
        return self._client

    @property
    def collection(self):
        """è·å–æˆ–åˆ›å»ºé›†åˆ"""
        if self._collection is None:
            self._collection = self.client.get_or_create_collection(
                name="codexlens_symbols",
                metadata={"hnsw:space": "cosine"}
            )
        return self._collection

    def upsert(
        self,
        id: str,
        embedding: List[float],
        metadata: Dict[str, Any],
        document: str = ""
    ):
        """æ’å…¥æˆ–æ›´æ–°å‘é‡"""
        self.collection.upsert(
            ids=[id],
            embeddings=[embedding],
            metadatas=[metadata],
            documents=[document]
        )

    def upsert_batch(
        self,
        ids: List[str],
        embeddings: List[List[float]],
        metadatas: List[Dict[str, Any]],
        documents: List[str] = None
    ):
        """æ‰¹é‡æ’å…¥"""
        self.collection.upsert(
            ids=ids,
            embeddings=embeddings,
            metadatas=metadatas,
            documents=documents or [""] * len(ids)
        )

    def search(
        self,
        query_embedding: List[float],
        limit: int = 10,
        where: Optional[Dict] = None
    ) -> List[Dict]:
        """å‘é‡ç›¸ä¼¼åº¦æœç´¢"""
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=limit,
            where=where,
            include=["metadatas", "distances", "documents"]
        )

        # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
        items = []
        for i in range(len(results["ids"][0])):
            items.append({
                "id": results["ids"][0][i],
                "metadata": results["metadatas"][0][i],
                "distance": results["distances"][0][i],
                "document": results["documents"][0][i] if results["documents"] else ""
            })

        return items

    def delete(self, ids: List[str]):
        """åˆ é™¤å‘é‡"""
        self.collection.delete(ids=ids)

    def count(self) -> int:
        """è·å–å‘é‡æ•°é‡"""
        return self.collection.count()
```

---

## 8. CLI å‘½ä»¤è®¾è®¡

### 8.1 ä¸»å…¥å£ (`cli/main.py`)

```python
import typer
from typing import Optional
from pathlib import Path

from .commands import init, search, find, symbol, inspect, graph, semantic, status
from .output import JSONOutput

app = typer.Typer(
    name="codexlens",
    help="Code intelligence tool for symbol search, semantic search, and dependency analysis.",
    add_completion=False
)

# å…¨å±€é€‰é¡¹
json_option = typer.Option(False, "--json", "-j", help="Output as JSON")
project_option = typer.Option(None, "--project", "-p", help="Project root path")

# æ³¨å†Œå­å‘½ä»¤
app.command()(init.command)
app.command()(search.command)
app.command()(find.command)
app.command()(symbol.command)
app.command()(inspect.command)
app.command()(graph.command)
app.command()(semantic.command)
app.command()(status.command)

def main():
    app()

if __name__ == "__main__":
    main()
```

### 8.2 è¾“å‡ºæ ¼å¼åŒ– (`cli/output.py`)

```python
import json
import sys
from typing import Any, Dict, List, Optional
from dataclasses import dataclass, asdict

@dataclass
class CLIResponse:
    """CLI å“åº”ç»“æ„"""
    success: bool
    data: Optional[Dict[str, Any]] = None
    error: Optional[Dict[str, str]] = None

    def to_json(self) -> str:
        """è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²"""
        result = {"success": self.success}
        if self.data:
            result["data"] = self.data
        if self.error:
            result["error"] = self.error
        return json.dumps(result, indent=2, ensure_ascii=False)

    def print(self, as_json: bool = False):
        """è¾“å‡ºç»“æœ"""
        if as_json:
            print(self.to_json())
        else:
            self._print_human_readable()

    def _print_human_readable(self):
        """äººç±»å¯è¯»æ ¼å¼è¾“å‡º"""
        if not self.success:
            print(f"Error: {self.error.get('message', 'Unknown error')}", file=sys.stderr)
            if suggestion := self.error.get('suggestion'):
                print(f"Suggestion: {suggestion}", file=sys.stderr)
            return

        if not self.data:
            print("No results")
            return

        # æ ¹æ®æ•°æ®ç±»å‹æ ¼å¼åŒ–è¾“å‡º
        if "results" in self.data:
            for item in self.data["results"]:
                self._print_result_item(item)
        elif "stats" in self.data:
            self._print_stats(self.data["stats"])
        else:
            print(json.dumps(self.data, indent=2))

    def _print_result_item(self, item: Dict):
        """æ‰“å°å•ä¸ªç»“æœé¡¹"""
        if "file_path" in item and "line" in item:
            # æœç´¢ç»“æœ
            print(f"{item['file_path']}:{item['line']}")
            if "content" in item:
                print(f"  {item['content']}")
        elif "symbol_id" in item:
            # ç¬¦å·ç»“æœ
            print(f"{item['type']}: {item['name']}")
            print(f"  Location: {item['file_path']}:{item['line_start']}")
            if item.get("signature"):
                print(f"  Signature: {item['signature']}")
        print()

    def _print_stats(self, stats: Dict):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("Index Statistics:")
        print(f"  Files: {stats.get('files', 0)}")
        print(f"  Symbols: {stats.get('symbols', 0)}")
        print(f"  Relations: {stats.get('relations', 0)}")
        if languages := stats.get("languages"):
            print("  Languages:")
            for lang, count in languages.items():
                print(f"    {lang}: {count}")


def success(data: Dict[str, Any]) -> CLIResponse:
    """åˆ›å»ºæˆåŠŸå“åº”"""
    return CLIResponse(success=True, data=data)


def error(code: str, message: str, suggestion: str = None) -> CLIResponse:
    """åˆ›å»ºé”™è¯¯å“åº”"""
    err = {"code": code, "message": message}
    if suggestion:
        err["suggestion"] = suggestion
    return CLIResponse(success=False, error=err)
```

### 8.3 å‘½ä»¤ç¤ºä¾‹: search (`cli/commands/search.py`)

```python
import typer
from typing import Optional, List
from pathlib import Path
import time

from ..output import success, error, CLIResponse
from ...engine.searcher import Searcher
from ...core.config import ProjectConfig
from ...utils.ripgrep import ripgrep_search

def command(
    query: str = typer.Argument(..., help="Search query (text or regex)"),
    path: Optional[str] = typer.Option(None, "--path", "-p", help="Path filter (glob)"),
    regex: bool = typer.Option(False, "--regex", "-r", help="Treat query as regex"),
    context: int = typer.Option(2, "--context", "-C", help="Context lines"),
    limit: int = typer.Option(50, "--limit", "-l", help="Max results"),
    json_output: bool = typer.Option(False, "--json", "-j", help="JSON output"),
    project: Optional[Path] = typer.Option(None, "--project", help="Project root")
):
    """
    Search code content using text or regex patterns.

    Uses ripgrep for fast searching with optional context lines.

    Examples:
        codexlens search "handleRequest"
        codexlens search "def.*test" --regex
        codexlens search "TODO" --path "**/*.py"
    """
    start_time = time.time()

    try:
        # ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
        project_root = project or Path.cwd()

        # æ£€æŸ¥é¡¹ç›®æ˜¯å¦å·²åˆå§‹åŒ–
        config_path = project_root / ".codexlens" / "config.toml"
        if not config_path.exists():
            response = error(
                "PROJECT_NOT_INITIALIZED",
                "Project not initialized",
                f"Run: codexlens init {project_root}"
            )
            response.print(json_output)
            raise typer.Exit(1)

        # æ‰§è¡Œæœç´¢
        results = ripgrep_search(
            query=query,
            path=project_root,
            pattern_filter=path,
            is_regex=regex,
            context_lines=context,
            max_results=limit
        )

        elapsed_ms = int((time.time() - start_time) * 1000)

        response = success({
            "results": results,
            "metadata": {
                "query": query,
                "mode": "regex" if regex else "literal",
                "count": len(results),
                "elapsed_ms": elapsed_ms
            }
        })
        response.print(json_output)

    except Exception as e:
        response = error("SEARCH_FAILED", str(e))
        response.print(json_output)
        raise typer.Exit(1)
```

### 8.4 å‘½ä»¤ç¤ºä¾‹: symbol (`cli/commands/symbol.py`)

```python
import typer
from typing import Optional
from pathlib import Path
import time

from ..output import success, error
from ...storage.sqlite_store import SQLiteStore
from ...core.config import ProjectConfig

def command(
    query: str = typer.Argument(..., help="Symbol name to search"),
    mode: str = typer.Option("fuzzy", "--mode", "-m", help="Search mode: exact, fuzzy"),
    type_filter: Optional[str] = typer.Option(None, "--type", "-t", help="Filter by type: function, class, method"),
    limit: int = typer.Option(50, "--limit", "-l", help="Max results"),
    relations: bool = typer.Option(False, "--relations", "-r", help="Include relations"),
    json_output: bool = typer.Option(False, "--json", "-j", help="JSON output"),
    project: Optional[Path] = typer.Option(None, "--project", help="Project root")
):
    """
    Search for code symbols (functions, classes, methods).

    Examples:
        codexlens symbol "UserService"
        codexlens symbol "handle" --mode fuzzy
        codexlens symbol "test_" --type function
    """
    start_time = time.time()

    try:
        project_root = project or Path.cwd()
        db_path = project_root / ".codexlens" / "index.db"

        if not db_path.exists():
            response = error(
                "INDEX_NOT_FOUND",
                "Index not found",
                f"Run: codexlens init {project_root}"
            )
            response.print(json_output)
            raise typer.Exit(1)

        store = SQLiteStore(db_path)

        # æœç´¢ç¬¦å·
        if mode == "exact":
            symbol = store.find_symbol_by_name(query, exact=True)
            symbols = [symbol] if symbol else []
        else:
            symbols = store.search_symbols(query, limit=limit)

        # ç±»å‹è¿‡æ»¤
        if type_filter:
            symbols = [s for s in symbols if s.type.value == type_filter]

        # æ„å»ºç»“æœ
        results = []
        for sym in symbols[:limit]:
            item = {
                "symbol_id": sym.id,
                "name": sym.name,
                "type": sym.type.value,
                "file_path": sym.location.file_path,
                "line_start": sym.location.line_start,
                "line_end": sym.location.line_end,
                "signature": sym.signature,
                "docstring": sym.docstring,
                "language": sym.language
            }

            # åŒ…å«å…³ç³»
            if relations:
                rels = store.get_relations(sym.id)
                item["relations"] = {
                    "callers": [r.source_id for r in rels if r.relation_type == "calls" and r.target_id == sym.id],
                    "callees": [r.target_id for r in rels if r.relation_type == "calls" and r.source_id == sym.id]
                }

            results.append(item)

        elapsed_ms = int((time.time() - start_time) * 1000)

        response = success({
            "results": results,
            "metadata": {
                "query": query,
                "mode": mode,
                "count": len(results),
                "elapsed_ms": elapsed_ms
            }
        })
        response.print(json_output)

    except Exception as e:
        response = error("SYMBOL_SEARCH_FAILED", str(e))
        response.print(json_output)
        raise typer.Exit(1)
```

---

## 9. å¼€å‘è·¯çº¿å›¾

### Phase 1: åŸºç¡€æ¡†æ¶ (Week 1-2)

**ç›®æ ‡**: å¯è¿è¡Œçš„ CLI éª¨æ¶ + åŸºç¡€æœç´¢

**ä»»åŠ¡æ¸…å•**:
- [ ] é¡¹ç›®éª¨æ¶æ­å»º (pyproject.toml, ç›®å½•ç»“æ„)
- [ ] æ ¸å¿ƒå®ä½“å®šä¹‰ (entities.py, config.py)
- [ ] CLI æ¡†æ¶ (Typer é›†æˆ)
- [ ] JSON è¾“å‡ºåè®®å®ç°
- [ ] ripgrep åŒ…è£…å™¨
- [ ] `init` å‘½ä»¤å®ç°
- [ ] `search` å‘½ä»¤å®ç° (ripgrep åç«¯)
- [ ] `find` å‘½ä»¤å®ç° (glob)
- [ ] `status` å‘½ä»¤å®ç°

**é‡Œç¨‹ç¢‘**: `codexlens search "pattern" --json` å¯å·¥ä½œ

**äº¤ä»˜ç‰©**:
```bash
codexlens init /path/to/project
codexlens search "function" --json
codexlens find "**/*.py" --json
codexlens status --json
```

---

### Phase 2: æ·±åº¦ç´¢å¼• (Week 3-4)

**ç›®æ ‡**: AST è§£æ + ç¬¦å·æå– + SQLite å­˜å‚¨

**ä»»åŠ¡æ¸…å•**:
- [ ] SQLite å­˜å‚¨å±‚å®ç°
- [ ] æ–‡ä»¶å“ˆå¸Œç¼“å­˜ (å¢é‡ç´¢å¼•)
- [ ] Python è§£æå™¨ (ast æ¨¡å—)
- [ ] JavaScript/TypeScript è§£æå™¨ (tree-sitter)
- [ ] Rust è§£æå™¨ (tree-sitter)
- [ ] é€šç”¨å›é€€è§£æå™¨
- [ ] è§£æå™¨å·¥å‚
- [ ] ç´¢å¼•å¼•æ“ç¼–æ’å™¨
- [ ] `symbol` å‘½ä»¤å®ç°
- [ ] `inspect` å‘½ä»¤å®ç°

**é‡Œç¨‹ç¢‘**: `codexlens symbol "ClassName"` è¿”å›ç¬¦å·è¯¦æƒ…

**äº¤ä»˜ç‰©**:
```bash
codexlens symbol "handleRequest" --json
codexlens inspect src/main.py --json
```

---

### Phase 3: å…³ç³»å›¾è°± (Week 5)

**ç›®æ ‡**: è°ƒç”¨å…³ç³»è§£æ + å›¾æŸ¥è¯¢

**ä»»åŠ¡æ¸…å•**:
- [ ] è°ƒç”¨å…³ç³»æå– (pending_calls è§£æ)
- [ ] å…³ç³»å­˜å‚¨ (relations è¡¨)
- [ ] NetworkX å›¾æ„å»º
- [ ] å›¾éå†ç®—æ³• (BFS/DFS)
- [ ] `graph` å‘½ä»¤å®ç°
- [ ] å½±å“åˆ†æåŠŸèƒ½

**é‡Œç¨‹ç¢‘**: `codexlens graph "Symbol" --direction callers` è¿”å›è°ƒç”¨é“¾

**äº¤ä»˜ç‰©**:
```bash
codexlens graph "UserService.login" --depth 3 --json
codexlens graph "handleError" --direction callees --json
```

---

### Phase 4: CCW é›†æˆ (Week 6)

**ç›®æ ‡**: CCW å·¥å…·åŒ…è£…å™¨ + ç«¯åˆ°ç«¯æµ‹è¯•

**ä»»åŠ¡æ¸…å•**:
- [ ] CCW å·¥å…·åŒ…è£…å™¨ (codex-lens.js)
- [ ] æ³¨å†Œåˆ° CCW å·¥å…·ç³»ç»Ÿ
- [ ] å‚æ•°éªŒè¯ä¸è½¬æ¢
- [ ] é”™è¯¯å¤„ç†ä¸é‡è¯•
- [ ] é›†æˆæµ‹è¯•
- [ ] æ–‡æ¡£æ›´æ–°

**é‡Œç¨‹ç¢‘**: `ccw tool exec codex_lens '{"command": "search", "query": "test"}'` å¯å·¥ä½œ

**äº¤ä»˜ç‰©**:
```bash
ccw tool exec codex_lens '{"command": "symbol", "query": "handleRequest"}'
ccw tool list | grep codex_lens
```

---

### Phase 5: è¯­ä¹‰æœç´¢ (Week 7-8) [å¯é€‰]

**ç›®æ ‡**: è‡ªç„¶è¯­è¨€ä»£ç æœç´¢

**ä»»åŠ¡æ¸…å•**:
- [ ] sentence-transformers é›†æˆ
- [ ] ChromaDB å‘é‡å­˜å‚¨
- [ ] ä»£ç åˆ†å—ç­–ç•¥
- [ ] åµŒå…¥ç”Ÿæˆç®¡é“
- [ ] å‘é‡ç´¢å¼•æ„å»º
- [ ] `semantic` å‘½ä»¤å®ç°
- [ ] æ··åˆæœç´¢ (å…³é”®è¯ + è¯­ä¹‰)

**é‡Œç¨‹ç¢‘**: `codexlens semantic "authentication logic"` è¿”å›ç›¸å…³ä»£ç 

**äº¤ä»˜ç‰©**:
```bash
codexlens semantic "user authentication middleware" --json
codexlens semantic "error handling" --limit 10 --json
```

---

### Phase 6: npm åˆ†å‘ (Week 9)

**ç›®æ ‡**: npm åŒ…è£…ä¸åˆ†å‘

**ä»»åŠ¡æ¸…å•**:
- [ ] PyInstaller é…ç½®
- [ ] å¤šå¹³å°æ„å»º (Windows, macOS, Linux)
- [ ] GitHub Actions CI/CD
- [ ] npm åŒ…è£…å™¨
- [ ] å®‰è£…è„šæœ¬
- [ ] æ–‡æ¡£ä¸ç¤ºä¾‹

**é‡Œç¨‹ç¢‘**: `npm install -g codexlens` å¯å·¥ä½œ

---

## 10. æŠ€æœ¯ä¾èµ–

### 10.1 æ ¸å¿ƒä¾èµ–

```toml
[project]
name = "codex-lens"
version = "0.1.0"
requires-python = ">=3.10"

dependencies = [
    # CLI æ¡†æ¶
    "typer>=0.9.0",
    "rich>=13.0.0",

    # é…ç½®
    "pydantic>=2.0.0",
    "tomli>=2.0.0",
    "tomli-w>=1.0.0",

    # ä»£ç è§£æ
    "tree-sitter>=0.20.0",
    "tree-sitter-python>=0.20.0",
    "tree-sitter-javascript>=0.20.0",
    "tree-sitter-typescript>=0.20.0",
    "tree-sitter-rust>=0.20.0",

    # å›¾åˆ†æ
    "networkx>=3.0",
]

[project.optional-dependencies]
semantic = [
    "sentence-transformers>=2.2.0",
    "chromadb>=0.4.0",
]

dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "mypy>=1.0.0",
    "ruff>=0.1.0",
]

[project.scripts]
codexlens = "codex_lens.cli.main:main"
```

### 10.2 å¤–éƒ¨å·¥å…·ä¾èµ–

| å·¥å…· | ç”¨é€” | å®‰è£…æ–¹å¼ |
|------|------|----------|
| ripgrep (rg) | å¿«é€Ÿæ–‡æœ¬æœç´¢ | `scoop install ripgrep` / `brew install ripgrep` |
| git | æ–‡ä»¶å‘ç° | ç³»ç»Ÿè‡ªå¸¦ |

---

## 11. npm åˆ†å‘ç­–ç•¥

### 11.1 PyInstaller é…ç½® (`codexlens.spec`)

```python
# -*- mode: python ; coding: utf-8 -*-
from PyInstaller.utils.hooks import collect_all

block_cipher = None

# æ”¶é›† tree-sitter è¯­è¨€ç»‘å®š
datas = []
binaries = []
hiddenimports = [
    'tree_sitter_python',
    'tree_sitter_javascript',
    'tree_sitter_typescript',
    'tree_sitter_rust',
]

for pkg in hiddenimports:
    try:
        d, b, h = collect_all(pkg)
        datas += d
        binaries += b
    except Exception:
        pass

a = Analysis(
    ['src/codex_lens/__main__.py'],
    pathex=['src'],
    binaries=binaries,
    datas=datas,
    hiddenimports=hiddenimports,
    hookspath=[],
    hooksconfig={},
    runtime_hooks=[],
    excludes=['tkinter', 'matplotlib'],
    win_no_prefer_redirects=False,
    win_private_assemblies=False,
    cipher=block_cipher,
    noarchive=False,
)

pyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)

exe = EXE(
    pyz,
    a.scripts,
    a.binaries,
    a.zipfiles,
    a.datas,
    [],
    name='codexlens',
    debug=False,
    bootloader_ignore_signals=False,
    strip=False,
    upx=True,
    upx_exclude=[],
    runtime_tmpdir=None,
    console=True,
    disable_windowed_traceback=False,
    argv_emulation=False,
    target_arch=None,
    codesign_identity=None,
    entitlements_file=None,
)
```

### 11.2 GitHub Actions æ„å»º

```yaml
# .github/workflows/build.yml
name: Build Binaries

on:
  push:
    tags:
      - 'v*'

jobs:
  build:
    strategy:
      matrix:
        include:
          - os: ubuntu-latest
            artifact: codexlens-linux-x64
          - os: windows-latest
            artifact: codexlens-win-x64.exe
          - os: macos-latest
            artifact: codexlens-macos-x64

    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"
          pip install pyinstaller

      - name: Build binary
        run: pyinstaller codexlens.spec

      - name: Rename artifact
        shell: bash
        run: |
          cd dist
          if [ "${{ runner.os }}" == "Windows" ]; then
            mv codexlens.exe ../${{ matrix.artifact }}
          else
            mv codexlens ../${{ matrix.artifact }}
          fi

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.artifact }}
          path: ${{ matrix.artifact }}

  release:
    needs: build
    runs-on: ubuntu-latest

    steps:
      - uses: actions/download-artifact@v4

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          files: |
            codexlens-linux-x64/codexlens-linux-x64
            codexlens-win-x64.exe/codexlens-win-x64.exe
            codexlens-macos-x64/codexlens-macos-x64
```

### 11.3 npm åŒ…ç»“æ„

```
npm-codexlens/
â”œâ”€â”€ package.json
â”œâ”€â”€ bin/
â”‚   â””â”€â”€ cli.js
â””â”€â”€ scripts/
    â””â”€â”€ install.js
```

**package.json**:
```json
{
  "name": "codexlens",
  "version": "0.1.0",
  "description": "Code intelligence tool for symbol search and dependency analysis",
  "bin": {
    "codexlens": "bin/cli.js"
  },
  "scripts": {
    "postinstall": "node scripts/install.js"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/user/codex-lens.git"
  },
  "os": ["darwin", "linux", "win32"],
  "cpu": ["x64", "arm64"]
}
```

---

## é™„å½• A: å‘½ä»¤é€ŸæŸ¥è¡¨

| å‘½ä»¤ | æè¿° | ç¤ºä¾‹ |
|------|------|------|
| `init` | åˆå§‹åŒ–é¡¹ç›®ç´¢å¼• | `codexlens init .` |
| `search` | æ–‡æœ¬/æ­£åˆ™æœç´¢ | `codexlens search "TODO" --path "**/*.py"` |
| `find` | æ–‡ä»¶æŸ¥æ‰¾ | `codexlens find "**/*.test.ts"` |
| `symbol` | ç¬¦å·æŸ¥æ‰¾ | `codexlens symbol "handleRequest" --relations` |
| `inspect` | æ–‡ä»¶/ç¬¦å·è¯¦æƒ… | `codexlens inspect src/main.py` |
| `graph` | è°ƒç”¨å…³ç³»å›¾ | `codexlens graph "UserService" --depth 3` |
| `semantic` | è¯­ä¹‰æœç´¢ | `codexlens semantic "authentication logic"` |
| `status` | ç´¢å¼•çŠ¶æ€ | `codexlens status` |

---

## é™„å½• B: CCW è°ƒç”¨ç¤ºä¾‹

```bash
# åˆå§‹åŒ–é¡¹ç›®
ccw tool exec codex_lens '{"command": "init", "projectPath": "/path/to/project"}'

# æœç´¢ä»£ç 
ccw tool exec codex_lens '{"command": "search", "query": "handleRequest", "limit": 20}'

# æŸ¥æ‰¾ç¬¦å·
ccw tool exec codex_lens '{"command": "symbol", "query": "UserService", "includeRelations": true}'

# è·å–è°ƒç”¨å›¾
ccw tool exec codex_lens '{"command": "graph", "query": "login", "depth": 2, "direction": "callers"}'

# è¯­ä¹‰æœç´¢
ccw tool exec codex_lens '{"command": "semantic", "query": "user authentication middleware"}'
```

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0.0*
*æœ€åæ›´æ–°: 2024-12*
